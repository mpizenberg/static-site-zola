+++
title = "Outlining Objects for Interactive Segmentation on Touch Devices"
date = 2017-10-27
template = "research-item.html"

[extra]
authors = ["Matthieu Pizenberg", "Axel Carlier", "Emmanuel Faure", "Vincent Charvillat"]
publication = "ACM Multimedia 2017"
links = [
    {name = "Paper", url = "https://mpizenberg.github.io/resources/otis/outlining-objects-interactive.pdf"},
    {name = "Code", url = "https://github.com/mpizenberg/otis"},
    {name = "Poster", url = "https://mpizenberg.github.io/resources/otis/poster-mm17.pdf"},
    {name = "Demo", url = "http://mm17-otis.pizenberg.fr/"}
]
header = "acmmm_17.jpg"
+++

### Abstract

Interactive segmentation consists in building a pixel-wise partition of an image, into foreground and background regions, with the help of user inputs. Most state-of-the-art algorithms use scribble-based interactions to build foreground and background models, and very few of these work focus on the usability of the scribbling interaction. In this paper we study the outlining interaction, which is very intuitive to non-expert users on touch devices. We present an algorithm, built upon the existing GrabCut algorithm, which infers both foreground and background models out of a single outline. We conducted a user study on 20 participants to demonstrate the usability of this interaction, and its performance for the task of interactive segmentation.
